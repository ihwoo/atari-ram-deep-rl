{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "import random\n",
    "import math\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-09 14:43:10,390] Making new env: Breakout-ram-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 63  63  63  63  63  63 255 255 255 255 255 255 255 255 255 255 255 255\n",
      " 255 255 255 255 255 255 255 255 255 255 255 255 192 192 192 192 192 192\n",
      " 255 255 255 255 255 255 255 255 255 255 255 255 255 240   0   0 255   0\n",
      "   0 240   0   5   0   0   6   0  70 182 134 198  22  38  54  70  88   6\n",
      " 146   0   8   0   0   0   0   0   0 241   0 242   0 242  25 241   5 242\n",
      "   0   0 255   0 228   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   8   0 255 255 255 255 255 255 255   0   0   5   0   0 186 214 117 246\n",
      " 219 242]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Breakout-ram-v0')\n",
    "observation = env.reset()\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None) \n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_bits(byte_list):\n",
    "    return np.array([b>>i & 1 for i in range(8) for b in byte_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.l1 = nn.Linear(128, 1024)\n",
    "        self.l2 = nn.Linear(1024, 256)\n",
    "        self.l3 = nn.Linear(256, 64)\n",
    "        self.l4 = nn.Linear(64, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = F.tanh(self.l1(x))\n",
    "        y = F.tanh(self.l2(y))\n",
    "        y = F.tanh(self.l3(y))\n",
    "        return self.l4(y)\n",
    "\n",
    "class xorbitDQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(xorbitDQN, self).__init__()\n",
    "        self.l1 = nn.Linear(2048, 4096)\n",
    "        self.l2 = nn.Linear(4096, 1024)\n",
    "        self.l3 = nn.Linear(1024, 64)\n",
    "        self.l4 = nn.Linear(64, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = F.leaky_relu(self.l1(x))\n",
    "        y = F.leaky_relu(self.l2(y))\n",
    "        y = F.leaky_relu(self.l3(y))\n",
    "        return self.l4(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xorbitDQN (\n",
       "  (l1): Linear (2048 -> 4096)\n",
       "  (l2): Linear (4096 -> 1024)\n",
       "  (l3): Linear (1024 -> 64)\n",
       "  (l4): Linear (64 -> 6)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xorbitDQN()\n",
    "memory = ReplayMemory(10000)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "#     eps_threshold = 1\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        return model(Variable(state.view(1, len(state)).clone().type(dtype), volatile=True)).data.max(1)[1].cpu()\n",
    "    else:\n",
    "        return torch.LongTensor([[env.action_space.sample()]])\n",
    "\n",
    "def plot_scores():\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    scores_t = torch.Tensor(episode_scores)\n",
    "    plt.plot(scores_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(scores_t) >= 100:\n",
    "        means = scores_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions)) \n",
    "\n",
    "    non_final_mask = torch.ByteTensor(tuple(map(lambda s: s is not None, batch.next_state)))\n",
    "    non_final_next_states_t = torch.stack(tuple(s for s in batch.next_state if s is not None)).type(dtype)\n",
    "    non_final_next_states = Variable(non_final_next_states_t, volatile=True)\n",
    "    state_batch = Variable(torch.stack(batch.state))\n",
    "    action_batch = Variable(torch.stack(batch.action).squeeze(2))\n",
    "    reward_batch = Variable(torch.stack(batch.reward))\n",
    "\n",
    "    if USE_CUDA:\n",
    "        state_batch = state_batch.cuda()\n",
    "        action_batch = action_batch.cuda()\n",
    "    state_action_values = model(state_batch).gather(1, action_batch).cpu()\n",
    "\n",
    "    next_state_values = Variable(torch.zeros(BATCH_SIZE))\n",
    "    next_state_values[non_final_mask] = model(non_final_next_states).max(1)[0].cpu()\n",
    "    next_state_values.volatile = False\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CudaSmoothL1Criterion_updateOutput received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, torch.FloatTensor, torch.cuda.FloatTensor, bool), but expected (int state, torch.cuda.FloatTensor input, torch.cuda.FloatTensor target, torch.cuda.FloatTensor output, bool sizeAverage)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-8dfc41c0f508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-b087845de302>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mexpected_state_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_state_values\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_state_action_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicholas/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msmooth_l1_loss\u001b[0;34m(input, target, size_average)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSmoothL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicholas/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         getattr(self._backend, update_output.name)(self._backend.library_state, input, target,\n\u001b[0;32m---> 41\u001b[0;31m                                                    output, *self.additional_args)\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: CudaSmoothL1Criterion_updateOutput received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, torch.FloatTensor, torch.cuda.FloatTensor, bool), but expected (int state, torch.cuda.FloatTensor input, torch.cuda.FloatTensor target, torch.cuda.FloatTensor output, bool sizeAverage)"
     ]
    }
   ],
   "source": [
    "episode_scores = []\n",
    "for i_episode in count(1):\n",
    "\n",
    "    ram = to_bits(env.reset())\n",
    "    state = torch.from_numpy(np.concatenate((ram, np.zeros(len(ram))))).float()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        next_ram, reward, done, _ = env.step(action[0,0])\n",
    "        reward = torch.Tensor([reward])\n",
    "        \n",
    "        next_ram = to_bits(next_ram)\n",
    "        xor = np.bitwise_xor(next_ram, ram)\n",
    "        next_state = torch.from_numpy(np.concatenate((next_ram, xor))).float()\n",
    "        \n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        # Move to the next state\n",
    "        ram = next_ram\n",
    "        \n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        \n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            episode_scores.append(total_reward[0])\n",
    "            plot_scores()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
